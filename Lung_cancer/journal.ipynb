{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting nodules and lables \n",
    "\n",
    "For all 9 features of the annotations\n",
    "\n",
    "The Lung Image Database Consortium image collection (LIDC-IDRI) consists of diagnostic and lung cancer screening thoracic computed tomography (CT) scans with marked-up annotated lesions. This database consists of 3-D CT scans along with an xml file for each patient. This xml files contains unblinded and blinded markings from 4 different radiologists. The masses detected are categorized into three different types.\n",
    "\n",
    "- Non-nodules\n",
    "- Nodules with diameters <3mm\n",
    "- Nodules with diameter > 3mm\n",
    "\n",
    "Each of these have a x,y,z demarcation of their centers. But only the nodules greater than 3mm diameter are considered for this study. These  xmls contains 9 different characteristics for nodules with diameter >3mm namely Subtlety, Calcification, Internal structure, Margin, Spiculation, Texture, Lobulation, Sphericity, Malignancy. Being able to learn to represent all of these characteristics of nodules would signify a good learnt representation.\n",
    "\n",
    "#### Extraction\n",
    "\n",
    "- We had scans were in a dicom format. We have firstly converted dicom to nifti and then converted nifti to nrrd format. The nrrd files have been converted to 3-d tensors.\n",
    "- We have calculated the max of the diameters of the nodules and hence extracted a box of dimensions 64x64x64 from the CT scans. \n",
    "    \n",
    "    - This step was necessary before training as the sizes of nodules compared to the size of lungs was very small and hence there would have been a lot of noise in the dataset for training.\n",
    "    - Also each CT scan had nx512x512 slices. Where n varied for each CT scan and hence it was difficult to extract nodules and send through a model which accepts a fixed size of input.\n",
    "\n",
    "However on extracting nodules from these scans we encountered a few difficulties due to the format of the dataset. \n",
    "Total number of annotations are 6859. Although the number of nodules might be less however all the annotations have been used during training.\n",
    "\n",
    "After extraction we observed a few anomalies and this is how we  have proceeded.\n",
    "\n",
    "- Each nodule has multiple annotations for each Nodule. In the format IL- IM etc for a single nodule. We have now considered all the annotations for each nodule for now in training. \n",
    "- As mentioned above the extracted nodules are of cubes of sizes 64x64x64. Although for some scans the nodule size  mx512x512 had m>n. These nodules have been skipped.\n",
    "- We are yet to correct a glitch on our side. If the distance from the center to the edge is less than 32 we have skipped the nodule for now.\n",
    "- 8 patients had two scans with different annotations and nodule numbers. Namely the patient id’s 132, 151, 315, 332, 355, 365, 442, 484. \n",
    "- Also during extraction we found that 2 patients namely the patient-id’s 238 and 585 have no nodules and all the characteristic fields were marked 0 and hence these two patients have been excluded. Reducing the total patient count from 1012 to 1010.\n",
    "- Patient id 777 has 127 annotations.\n",
    " \n",
    "Total number of patients with nodules>3mm are  875 and the total number of annotations for nodules>3mm are 6859.\n",
    "\n",
    "- The remaing patients:\n",
    "\n",
    "28\n",
    "32\n",
    "62\n",
    "71\n",
    "100\n",
    "143\n",
    "174\n",
    "189\n",
    "197\n",
    "205\n",
    "214\n",
    "218\n",
    "224\n",
    "225\n",
    "226\n",
    "238\n",
    "239\n",
    "253\n",
    "261\n",
    "279\n",
    "293\n",
    "295\n",
    "306\n",
    "307\n",
    "316\n",
    "322\n",
    "327\n",
    "330\n",
    "331\n",
    "333\n",
    "336\n",
    "342\n",
    "349\n",
    "361\n",
    "364\n",
    "382\n",
    "383\n",
    "389\n",
    "391\n",
    "401\n",
    "410\n",
    "417\n",
    "418\n",
    "422\n",
    "425\n",
    "428\n",
    "441\n",
    "446\n",
    "455\n",
    "465\n",
    "472\n",
    "482\n",
    "506\n",
    "511\n",
    "512\n",
    "513\n",
    "514\n",
    "519\n",
    "528\n",
    "531\n",
    "536\n",
    "540\n",
    "544\n",
    "548\n",
    "561\n",
    "564\n",
    "573\n",
    "585\n",
    "589\n",
    "600\n",
    "603\n",
    "612\n",
    "616\n",
    "622\n",
    "623\n",
    "627\n",
    "632\n",
    "646\n",
    "653\n",
    "665\n",
    "667\n",
    "668\n",
    "679\n",
    "683\n",
    "685\n",
    "689\n",
    "690\n",
    "691\n",
    "710\n",
    "711\n",
    "716\n",
    "718\n",
    "731\n",
    "737\n",
    "738\n",
    "745\n",
    "746\n",
    "755\n",
    "760\n",
    "764\n",
    "774\n",
    "784\n",
    "804\n",
    "808\n",
    "839\n",
    "853\n",
    "862\n",
    "876\n",
    "877\n",
    "878\n",
    "881\n",
    "885\n",
    "887\n",
    "889\n",
    "891\n",
    "897\n",
    "900\n",
    "901\n",
    "903\n",
    "918\n",
    "927\n",
    "930\n",
    "931\n",
    "934\n",
    "937\n",
    "948\n",
    "952\n",
    "954\n",
    "960\n",
    "964\n",
    "967\n",
    "970\n",
    "975\n",
    "979\n",
    "988\n",
    "992\n",
    "995\n",
    "\n",
    "\n",
    "#### Labels\n",
    "\n",
    "The labels have been extracted from the xml files associated with each patient from the associated xmls we have created a csv which stores patient\\_id nodule\\_id and all the 9 characteristics for 6859 annotations of nodules> 3mm. This csv is further converted to a tensor of size 6859x9 which is named all_labels.pt which is passed to the data loaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datasets as mt_datasets\n",
    "import transforms as mt_transforms\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "\n",
    "from utils import find\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import resnet\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datasets as mt_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/scratch/dj1311/Lung_cancer/LIDC_conversion5/\"\n",
    "\n",
    "img_list = []\n",
    "label_list = []\n",
    "my_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (dirpath, dirnames, filenames) in enumerate(os.walk(ROOT_DIR)):\n",
    "    if not dirnames:\n",
    "        # for 1 patient, all files\n",
    "        key = None\n",
    "        values = []\n",
    "\n",
    "        for f in filenames:            \n",
    "            if f.endswith(\".nii.gz\"):\n",
    "                if f.startswith(\"LIDC-IDRI\"):\n",
    "                    key = f\n",
    "                else:\n",
    "                    values.append(f)\n",
    "            \n",
    "        for value in values:\n",
    "            img_list.append(os.path.join(dirpath, key))\n",
    "            label_list.append(os.path.join(dirpath, value))\n",
    "            nodule_id = value.split(\".nrrd.nii.gz\")[0].split(\"Annotation\")[1]\n",
    "            patient_id = key.split(\"LIDC-IDRI-\")[1][0:4]\n",
    "            my_list.append((patient_id, nodule_id))\n",
    "\n",
    "\n",
    "img_list, label_list = img_list[6000:], label_list[6000:]\n",
    "# print(img_list, label_list)\n",
    "filename_pairs = list(zip(img_list, label_list))\n",
    "train_dataset = mt_datasets.MRI2DSegmentationDataset(filename_pairs, transform=mt_transforms.ToTensor())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32\n",
    "nodules = []\n",
    "all_labels = []\n",
    "\n",
    "f = open('dev', 'w')\n",
    "\n",
    "for i, patient in enumerate(train_dataset):\n",
    "    print(f\"Processing patient {i}.\")\n",
    "\n",
    "    if patient is None:\n",
    "        print(f\"Skipping {i}:\")\n",
    "        continue\n",
    "    gt = patient['gt']\n",
    "    inp = patient['input']\n",
    "    labels = find(*my_list[i])\n",
    "    if not labels:\n",
    "        print(f\"Skipping {i}: { patient['filename']}, {patient['gt_filename']}, without lables.\")\n",
    "        continue\n",
    "\n",
    "    depth = inp.shape[0]\n",
    "\n",
    "    idx = gt.nonzero()\n",
    "    min_, max_ =  idx.min(dim=0)[0], idx.max(dim=0)[0]\n",
    "    start, end = (min_ +  max_)/2 - C, (min_ +  max_)/2 + C\n",
    "    \n",
    "    s_x, s_y, s_z = start.tolist()\n",
    "    e_x, e_y, e_z = end.tolist()\n",
    "\n",
    "    if s_x < 0:\n",
    "        e_x += abs(s_x)\n",
    "        s_x = 0\n",
    "\n",
    "    if e_x > depth:\n",
    "        s_x -= (e_x - depth)\n",
    "        e_x = depth\n",
    "\n",
    "\n",
    "    if s_y < 0:\n",
    "        e_y += abs(s_y)\n",
    "        s_y = 0\n",
    "\n",
    "    if e_y > 512:\n",
    "        s_y -= (e_y - depth)\n",
    "        e_y = depth\n",
    "\n",
    "\n",
    "    if s_z < 0:\n",
    "        e_z += abs(s_z)\n",
    "        s_z = 0\n",
    "\n",
    "    if e_z > 512:\n",
    "        s_z -= (e_z - depth)\n",
    "        e_z = depth\n",
    "\n",
    "\n",
    "    nodule = (gt * inp)[s_x:e_x, s_y:e_y, s_z:e_z]\n",
    "    print(i, nodule.shape, patient['filename'], patient['gt_filename'], file=f)\n",
    "    f.flush()\n",
    "    if nodule.shape[0]== 64 and nodule.shape[1]== 64 and nodule.shape[2]== 64:\n",
    "        nodules.append(nodule.unsqueeze(0))\n",
    "        all_labels.append(torch.tensor(labels).unsqueeze(0))\n",
    "    else:\n",
    "        print(i,nodule.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodules = torch.cat(nodules)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "print(nodules.shape, all_labels.shape)\n",
    "\n",
    "torch.save(nodules, 'nodules6000:.pt')\n",
    "torch.save(all_labels, 'all_labels6000:.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loaders\n",
    "\n",
    "Designing the Data loader:- using the medical torch data loader as a guideline we create a data loader to load the tensors(after converting the nrrd to tensors). This data loader creates a pair of labels and the tensor of the nodule.A class named Data is created which returns a pair of tensor and a label corresponding to the particular nodule(all_labels.pt) whereas the tensor is loaded from nodule.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "nodules = torch.load('concat_nodules.pt')\n",
    "all_lables = torch.load('concat_lables.pt')\n",
    "\n",
    "batch_size = 32\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "\n",
    "def rotation(img):\n",
    "    i, j = random.randint(0, 2), random.randint(0, 2)\n",
    "    return img.transpose(i, j)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "dataset = mt_datasets.TensorDataset(nodules, all_lables)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "The model used is a Resnet10. The last fully connected layer has been fine tuned to give outputs for multi class prediction for 9 features. \n",
    "\n",
    "The model is a multi class-multi label classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "model = resnet.resnet18(sample_size=64, sample_duration=64, num_classes=[5])\n",
    "# num_ftrs = resnet18.fc.in_features\n",
    "# resnet18.fc = nn.Linear(num_ftrs, 5)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\"=\"*20)\n",
    "print('Training Started')\n",
    "print(\"=\"*20)\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "idx = 0\n",
    "y_true = []\n",
    "y_scores = []\n",
    "for epoch in range(epochs):\n",
    "    for i, (nodule, labels) in enumerate(train_loader):\n",
    "        nodule, labels = nodule[0].to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        nodule = nodule.unsqueeze(1)\n",
    "        nodule = torch.cat([nodule,nodule,nodule],dim=1)\n",
    "        labels = labels[:, -1] - 1\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(nodule)       \n",
    "      \n",
    "        loss = 0.0\n",
    "        for i, output in enumerate(outputs):\n",
    "            loss += criterion(output, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        writer.add_scalar('Loss/train', loss.item(), idx)\n",
    "        idx += 1\n",
    "\n",
    "    print(f\"Epochs: {epoch}, i = {i}, Loss = {loss.item()}\")\n",
    "    \n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the data\n",
    "\n",
    "The mean across all 9 features is:-\n",
    "\n",
    "    -subtlety              3.823787\n",
    "    -internalStructure     1.013992\n",
    "    -calcification         5.655152\n",
    "    -sphericity            3.783997\n",
    "    -margin                3.940825\n",
    "    -lobulation            1.699461\n",
    "    -spiculation           1.590439\n",
    "    -texture               4.419910\n",
    "    -malignancy            2.813147\n",
    "\n",
    "#### Count for each feature\n",
    "\n",
    "    Malignancy:- Counter({5: 691, 4: 962, 3: 2606, 2: 1580, 1: 1020, 0: 2})\n",
    "    Texture:- Counter({5: 5020, 4: 823, 2: 155, 1: 480, 3: 381, 0: 2})\n",
    "    Lobulation:-   Counter({3: 714, 5: 191, 1: 4117, 2: 1451, 4: 386, 0: 2})\n",
    "    Spiculation:- Counter({3: 517, 5: 253, 4: 269, 1: 4620, 2: 1200, 0: 2})\n",
    "    Margin:- Counter({2: 620, 4: 2149, 3: 896, 1: 364, 5: 2830, 0: 2})\n",
    "    Sphericity:- Counter({3: 2096, 4: 2316, 5: 1845, 2: 583, 1: 19, 0: 2})\n",
    "    Calcification:- Counter({6: 6017, 3: 709, 5: 75, 4: 42, 2: 12, 1: 4, 0: 2})\n",
    "    InternalStructure:- Counter({1: 6819, 2: 11, 4: 27, 5: 1, 3: 1, 0: 2})\n",
    "    Subtlety:- Counter({5: 2542, 1: 349, 2: 625, 4: 1897, 3: 1446, 0: 2})\n",
    "\n",
    "The data seems skewed as two patients have empty nodule annotations having values 0 for all the features. \n",
    "\n",
    "\n",
    "\n",
    "#### Calculating PRECISION RECALL \n",
    "\n",
    "Curves\n",
    "\n",
    "These curves help establish a trade off between true positive rate and the positive predictive value. These values are appropriate for imbalanced datasets.\n",
    "\n",
    "#### ROC curves\n",
    "\n",
    "Trade off between true positive rate and false positive rate.\n",
    "\n",
    "#### Area Under the curve\n",
    "The area under the curve is used as a summary for the model skill. A skillful model will assign  a higher probability to a randomly chosen real positive occurrence than a negative occurrence on average. SKillful models tend to blow up on top left of the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*20)\n",
    "print('Precision/Recall Calculation')\n",
    "print(\"=\"*20)\n",
    "\n",
    "\n",
    "y_test, y_scores = [], []\n",
    "for i, (nodule, labels) in enumerate(validation_loader):\n",
    "    nodule, labels = nodule[0].to(device), labels.to(device)\n",
    "\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    nodule = nodule.unsqueeze(1)\n",
    "    nodule = torch.cat([nodule,nodule,nodule],dim=1)\n",
    "    labels = labels[:, -1] - 1\n",
    "\n",
    "    # forward\n",
    "    outputs = model(nodule)[0]     \n",
    "\n",
    "    y_test.append(labels.detach().cpu())\n",
    "    y_scores.append(outputs.detach().cpu())\n",
    "\n",
    "\n",
    "y_test = torch.cat(y_test).numpy()\n",
    "y_scores = torch.cat(y_scores).numpy()\n",
    "\n",
    "\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
    "print(y_test.shape, y_scores.shape)\n",
    "# precision, recall, _, _ = precision_recall_fscore_support(y_test, y_scores)\n",
    "# print(precision, recall)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "n_classes = 5\n",
    "for i in range(n_classes):\n",
    "#     precision[i], recall[i], _, _ = precision_recall_fscore_support(y_test[:, i], y_scores[:, i])\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_scores[:, i])\n",
    "    # average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "    print(precision[i][300], recall[i][300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for precesion recall values for malignancy\n",
    "    \n",
    "         Precesion          Recall\n",
    "    -0:- 0.3333333333333333 0.8\n",
    "    -1:- 0.2925170068027211 0.6099290780141844\n",
    "    -2:- 0.4391891891891892 0.5909090909090909\n",
    "    -3:- 0.2033898305084746 0.759493670886076\n",
    "    -4:- 0.19387755102040816 0.8769230769230769\n",
    "    \n",
    "    Average precision score, micro-averaged over all classes: 0.41\n",
    "    \n",
    "#### Results for Area under the curve calculation\n",
    "\n",
    "The noted values after 100 epochs is:-\n",
    "\n",
    "Epoch: 99, Accuracy: 40.59405940594059\n",
    "\n",
    "For the malignancy label the value of area under the curve is:\n",
    "\n",
    "    -0: 0.8182831661092531\n",
    "    -1: 0.5827922077922078 \n",
    "    -2: 0.5278716216216217\n",
    "    -3: 0.45017482517482516\n",
    "    -4: 0.6417525773195877}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
