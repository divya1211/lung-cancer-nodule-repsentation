{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datasets as mt_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "nodules = torch.load('nodules.pt')\n",
    "malignancies = torch.load('malignancies.pt') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mt_datasets.TensorDataset(nodules, malignancies)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 5)\n",
    "resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0, i = 0, Loss = 1.777927041053772\n",
      "Epochs: 0, i = 1, Loss = 1.6741379499435425\n",
      "Epochs: 0, i = 2, Loss = 1.482314109802246\n",
      "Epochs: 0, i = 3, Loss = 2.0598957538604736\n",
      "Epochs: 0, i = 4, Loss = 1.3544490337371826\n",
      "Epochs: 0, i = 5, Loss = 1.2030029296875\n",
      "Epochs: 0, i = 6, Loss = 2.13533091545105\n",
      "Epochs: 0, i = 7, Loss = 2.137643337249756\n",
      "Epochs: 0, i = 8, Loss = 1.4781906604766846\n",
      "Epochs: 0, i = 9, Loss = 2.511857509613037\n",
      "Epochs: 0, i = 10, Loss = 1.1556068658828735\n",
      "Epochs: 0, i = 11, Loss = 1.5826786756515503\n",
      "Epochs: 0, i = 12, Loss = 1.8691275119781494\n",
      "Epochs: 0, i = 13, Loss = 1.461388349533081\n",
      "Epochs: 0, i = 14, Loss = 1.7714548110961914\n",
      "Epochs: 0, i = 15, Loss = 1.3291492462158203\n",
      "Epochs: 0, i = 16, Loss = 1.337815761566162\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "idx = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (nodule, malignancy) in enumerate(train_loader, 0):\n",
    "        nodule, malignancy = nodule.to(device), malignancy.to(device)\n",
    "\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        input = torch.cat([nodule.mean(dim=-1).unsqueeze(1), nodule.mean(dim=-2).unsqueeze(1), nodule.mean(dim=-3).unsqueeze(1)], dim=1)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(input)\n",
    "        loss = criterion(outputs, malignancy)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        writer.add_scalar('Loss/train', loss.item(), idx)\n",
    "        print(f\"Epochs: {epoch}, i = {i}, Loss = {loss.item()}\")\n",
    "        idx += 1\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        images, labels = data\n",
    "        outputs = resnet18(images)\n",
    "        print(len(outputs))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
